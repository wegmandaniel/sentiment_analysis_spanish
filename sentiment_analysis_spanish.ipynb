{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to create a sentiment analysis model that works directly in Spanish.  We will try different models and an ensemble of them to see which one works better. To train the models we will use data taken from the TASS webpage (http://tass.sepln.org/), it contains multiple datasets but we have combined all of them into one dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "\n",
    "import spacy\n",
    "from es_lemmatizer import lemmatize\n",
    "\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "from gensim import utils\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path0 = \"D:/sentiment_analysis/\"\n",
    "tweets_corpus = pd.read_csv(path0 + \"TASS_5_full.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>polarty_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@PauladeLasHeras No te libraras de ayudar me/n...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@marodriguezb Gracias MAR</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Off pensando en el regalito Sinde, la que se v...</td>\n",
       "      <td>N+</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conozco a alguien q es adicto al drama! Ja ja ...</td>\n",
       "      <td>P+</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toca @crackoviadeTV3 . Grabaci贸n dl especial N...</td>\n",
       "      <td>P+</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text polarity  polarty_val\n",
       "0  @PauladeLasHeras No te libraras de ayudar me/n...      NEU            0\n",
       "1                          @marodriguezb Gracias MAR        P            1\n",
       "2  Off pensando en el regalito Sinde, la que se v...       N+           -2\n",
       "3  Conozco a alguien q es adicto al drama! Ja ja ...       P+            2\n",
       "4  Toca @crackoviadeTV3 . Grabaci贸n dl especial N...       P+            2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen the dataset has 5 categories: very positive (P+), positive(P), neutral(NEU), negative(N) and very negative(N+). Since our intention is just to train a model with positive, negative and neutral, we will create three new columns. The first one contains very positive and positive(1), very negative and negative(-1), and neutral tweets(0). The second column tags with a one all negative and very negative tweets, while tags with 0 the rest. The third column does the same as the second one but the (very)positive tweets are the ones tagged with a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cat_columns(tweets_corpus, choices, name_res_column):\n",
    "    conditions = [\n",
    "        (tweets_corpus[\"polarity\"]  == 'P+'),\n",
    "        (tweets_corpus[\"polarity\"]  == 'P'),\n",
    "        (tweets_corpus[\"polarity\"]  == 'NEU'),\n",
    "        (tweets_corpus[\"polarity\"]  == 'N'),\n",
    "        (tweets_corpus[\"polarity\"]  == 'N+')]\n",
    "    tweets_corpus[name_res_column] = np.select(conditions, choices, default='NONE')\n",
    "    tweets_corpus[name_res_column] = tweets_corpus[name_res_column].astype(int)\n",
    "    return tweets_corpus\n",
    "\n",
    "\n",
    "tweets_corpus = create_cat_columns(tweets_corpus=tweets_corpus,\n",
    "                                   choices=[1, 1, 0, -1, -1],\n",
    "                                   name_res_column= \"polarity_3_val\")\n",
    "\n",
    "tweets_corpus = create_cat_columns(tweets_corpus=tweets_corpus,\n",
    "                                   choices=[0, 0, 0, 1, 1],\n",
    "                                   name_res_column= \"polarity_neg\")\n",
    "\n",
    "tweets_corpus = create_cat_columns(tweets_corpus=tweets_corpus,\n",
    "                                   choices=[1, 1, 0, 0, 0],\n",
    "                                   name_res_column= \"polarity_pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>polarty_val</th>\n",
       "      <th>polarity_3_val</th>\n",
       "      <th>polarity_neg</th>\n",
       "      <th>polarity_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@PauladeLasHeras No te libraras de ayudar me/n...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@marodriguezb Gracias MAR</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Off pensando en el regalito Sinde, la que se v...</td>\n",
       "      <td>N+</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conozco a alguien q es adicto al drama! Ja ja ...</td>\n",
       "      <td>P+</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toca @crackoviadeTV3 . Grabaci贸n dl especial N...</td>\n",
       "      <td>P+</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text polarity  polarty_val  \\\n",
       "0  @PauladeLasHeras No te libraras de ayudar me/n...      NEU            0   \n",
       "1                          @marodriguezb Gracias MAR        P            1   \n",
       "2  Off pensando en el regalito Sinde, la que se v...       N+           -2   \n",
       "3  Conozco a alguien q es adicto al drama! Ja ja ...       P+            2   \n",
       "4  Toca @crackoviadeTV3 . Grabaci贸n dl especial N...       P+            2   \n",
       "\n",
       "   polarity_3_val  polarity_neg  polarity_pos  \n",
       "0               0             0             0  \n",
       "1               1             0             1  \n",
       "2              -1             1             0  \n",
       "3               1             0             1  \n",
       "4               1             0             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is the preprocessing, we will clean the text column and lemmatize de words. It is very important to notice that the stopwords do not contain words like \"si\" and \"no\" (\"yes\" and \"no\"). These are words that are very important for sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_stop_words(list_new_stopwords, remove_words):\n",
    "    custom_stop_words = list(set(stopwords.words('spanish')))\n",
    "    custom_stop_words.extend(list_new_stopwords)\n",
    "    custom_stop_words = [word for word in custom_stop_words if word not in remove_words]\n",
    "    return custom_stop_words\n",
    "\n",
    "def lemmatizer(text):\n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)\n",
    "\n",
    "def clean_text(s):\n",
    "    filters = [gsp.strip_tags,\n",
    "               gsp.strip_punctuation,\n",
    "               gsp.strip_multiple_whitespaces,\n",
    "               gsp.strip_numeric]\n",
    "    s = re.sub(r'http\\S+', '', s)\n",
    "    s = s.lower()\n",
    "    s = utils.to_unicode(s)\n",
    "    s = utils.deaccent(s)\n",
    "    for f in filters:\n",
    "        s = f(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_nltk = set(stopwords.words('spanish'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "nlp.add_pipe(lemmatize, after=\"tagger\")\n",
    "\n",
    "\n",
    "list_new_stopwords = [\"aun\", \"ser\", \"ver\", \"hoy\", \"ustedes\", \"aqui\",\n",
    "                              \"vamos\", \"haber\", \"hacer\", \"tener\", \"ir\",\n",
    "                              \"decir\", \"comer\",\"asi\", \"pues\"]\n",
    "remove_words = [\"no\", \"si\", \"s铆\"]\n",
    "\n",
    "custom_stop_words = create_custom_stop_words(list_new_stopwords, remove_words)\n",
    "\n",
    "tweets_corpus[\"content_clean\"] =  tweets_corpus[\"text\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (custom_stop_words)]))\n",
    "tweets_corpus[\"content_clean\"] = tweets_corpus[\"content_clean\"].apply(lambda x: clean_text(x))\n",
    "tweets_corpus = tweets_corpus.dropna(subset=[\"content_clean\"])\n",
    "tweets_corpus[\"content_clean\"] = tweets_corpus[\"content_clean\"].replace('\\s+', ' ', regex=True)\n",
    "tweets_corpus[\"content_clean\"] = tweets_corpus[\"content_clean\"].replace(\"\", np.nan)\n",
    "tweets_corpus[\"content_clean\"] = tweets_corpus[\"content_clean\"].replace(\" \", np.nan)\n",
    "tweets_corpus = tweets_corpus.dropna(subset=[\"content_clean\"])\n",
    "\n",
    "tweets_corpus = tweets_corpus[tweets_corpus['content_clean'].apply(lambda x: len(x) > 3)]\n",
    "tweets_corpus.dropna(subset=['content_clean'], inplace=True)\n",
    "tweets_corpus.reset_index(drop=True, inplace=True)\n",
    "\n",
    "tweets_corpus[\"lemma_clean_text\"] = tweets_corpus[\"content_clean\"].apply(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>polarty_val</th>\n",
       "      <th>polarity_3_val</th>\n",
       "      <th>polarity_neg</th>\n",
       "      <th>polarity_pos</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>lemma_clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@PauladeLasHeras No te libraras de ayudar me/n...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pauladelasheras no libraras ayudar me nos bes...</td>\n",
       "      <td>pauladelasheras no libraras ayudar me nos be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@marodriguezb Gracias MAR</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>marodriguezb gracias mar</td>\n",
       "      <td>marodriguezb gracia mar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Off pensando en el regalito Sinde, la que se v...</td>\n",
       "      <td>N+</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>off pensando regalito sinde va sgae van corrup...</td>\n",
       "      <td>off pensar regalito sinde ir sgae ir corrupto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conozco a alguien q es adicto al drama! Ja ja ...</td>\n",
       "      <td>P+</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>conozco alguien q adicto drama ja ja ja suena ...</td>\n",
       "      <td>conocer alguien q adicto drama ja ja ja sonar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toca @crackoviadeTV3 . Grabaci贸n dl especial N...</td>\n",
       "      <td>P+</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>toca crackoviadetv grabacion dl especial navid...</td>\n",
       "      <td>toca crackoviadetv grabacion dl especial navid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text polarity  polarty_val  \\\n",
       "0  @PauladeLasHeras No te libraras de ayudar me/n...      NEU            0   \n",
       "1                          @marodriguezb Gracias MAR        P            1   \n",
       "2  Off pensando en el regalito Sinde, la que se v...       N+           -2   \n",
       "3  Conozco a alguien q es adicto al drama! Ja ja ...       P+            2   \n",
       "4  Toca @crackoviadeTV3 . Grabaci贸n dl especial N...       P+            2   \n",
       "\n",
       "   polarity_3_val  polarity_neg  polarity_pos  \\\n",
       "0               0             0             0   \n",
       "1               1             0             1   \n",
       "2              -1             1             0   \n",
       "3               1             0             1   \n",
       "4               1             0             1   \n",
       "\n",
       "                                       content_clean  \\\n",
       "0   pauladelasheras no libraras ayudar me nos bes...   \n",
       "1                           marodriguezb gracias mar   \n",
       "2  off pensando regalito sinde va sgae van corrup...   \n",
       "3  conozco alguien q adicto drama ja ja ja suena ...   \n",
       "4  toca crackoviadetv grabacion dl especial navid...   \n",
       "\n",
       "                                    lemma_clean_text  \n",
       "0    pauladelasheras no libraras ayudar me nos be...  \n",
       "1                            marodriguezb gracia mar  \n",
       "2  off pensar regalito sinde ir sgae ir corrupto ...  \n",
       "3  conocer alguien q adicto drama ja ja ja sonar ...  \n",
       "4  toca crackoviadetv grabacion dl especial navid...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P+     21888\n",
       "N      12562\n",
       "N+      5379\n",
       "P       2534\n",
       "NEU     1958\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus[\"polarity\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen the dataset is unbalanced when it comes to neutral tweets. This will be our biggest challenge.\n",
    "\n",
    "We will separate 5% of the total tweets so we can do a final metric checkup at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate 5% of posts for final checkup\n",
    "msk = np.random.rand(len(tweets_corpus)) < 0.9\n",
    "test_corpus = tweets_corpus[~msk]\n",
    "tweets_corpus = tweets_corpus[msk]\n",
    "tweets_corpus.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The next step is to train the models, we will use 7 different algorithms with the intention to find which one is the best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(train_fit, custom_stop_words):\n",
    "    vector = TfidfVectorizer(sublinear_tf=True, max_df=.9, stop_words=custom_stop_words)\n",
    "    vector.fit(train_fit)\n",
    "    return vector\n",
    "\n",
    "def create_train_test(tweets_corpus, col_name_label, col_name_text, custom_stop_words):\n",
    "    # Same tf vector will be used for Testing sentiments on unseen trending data\n",
    "    tf_vector = get_feature_vector(np.array(tweets_corpus.loc[:, col_name_text]).ravel(),\n",
    "                                   custom_stop_words)\n",
    "    X = tf_vector.transform(np.array(tweets_corpus.loc[:, col_name_text]).ravel())\n",
    "    y = np.array(tweets_corpus.loc[:, col_name_label]).ravel()\n",
    "    indices = list(tweets_corpus.index)\n",
    "    X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, indices, test_size=0.2, random_state=125)\n",
    "    return X_train, X_test, y_train, y_test, indices_train, indices_test, tf_vector\n",
    "\n",
    "def train_model(model_selected, X_train, X_test, y_train, y_test):\n",
    "    model = model_selected\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    print()\n",
    "    print(confusion_matrix(y_test, y_predict))\n",
    "    print()\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    return model, y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first attempt is to use the data which contains 3 labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[2855    0  376]\n",
      " [ 210    0  131]\n",
      " [ 406    1 4030]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.88      0.85      3231\n",
      "           0       0.00      0.00      0.00       341\n",
      "           1       0.89      0.91      0.90      4437\n",
      "\n",
      "    accuracy                           0.86      8009\n",
      "   macro avg       0.57      0.60      0.58      8009\n",
      "weighted avg       0.82      0.86      0.84      8009\n",
      "\n",
      "\n",
      "[[2831    0  400]\n",
      " [ 215    0  126]\n",
      " [ 387    0 4050]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.88      0.85      3231\n",
      "           0       0.00      0.00      0.00       341\n",
      "           1       0.89      0.91      0.90      4437\n",
      "\n",
      "    accuracy                           0.86      8009\n",
      "   macro avg       0.57      0.60      0.58      8009\n",
      "weighted avg       0.82      0.86      0.84      8009\n",
      "\n",
      "\n",
      "[[2730    0  501]\n",
      " [ 213    0  128]\n",
      " [ 521    1 3915]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.84      0.82      3231\n",
      "           0       0.00      0.00      0.00       341\n",
      "           1       0.86      0.88      0.87      4437\n",
      "\n",
      "    accuracy                           0.83      8009\n",
      "   macro avg       0.55      0.58      0.56      8009\n",
      "weighted avg       0.80      0.83      0.81      8009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wegma\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\wegma\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[2818    2  411]\n",
      " [ 199    5  137]\n",
      " [ 370    2 4065]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.87      0.85      3231\n",
      "           0       0.56      0.01      0.03       341\n",
      "           1       0.88      0.92      0.90      4437\n",
      "\n",
      "    accuracy                           0.86      8009\n",
      "   macro avg       0.76      0.60      0.59      8009\n",
      "weighted avg       0.85      0.86      0.84      8009\n",
      "\n",
      "\n",
      "[[ 610    0 2621]\n",
      " [  33    0  308]\n",
      " [  69    0 4368]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.19      0.31      3231\n",
      "           0       0.00      0.00      0.00       341\n",
      "           1       0.60      0.98      0.74      4437\n",
      "\n",
      "    accuracy                           0.62      8009\n",
      "   macro avg       0.49      0.39      0.35      8009\n",
      "weighted avg       0.68      0.62      0.54      8009\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wegma\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[2674   18  539]\n",
      " [ 188   11  142]\n",
      " [ 424   14 3999]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.83      0.82      3231\n",
      "           0       0.26      0.03      0.06       341\n",
      "           1       0.85      0.90      0.88      4437\n",
      "\n",
      "    accuracy                           0.83      8009\n",
      "   macro avg       0.64      0.59      0.59      8009\n",
      "weighted avg       0.81      0.83      0.82      8009\n",
      "\n",
      "\n",
      "[[2714   25  492]\n",
      " [ 194   14  133]\n",
      " [ 432   14 3991]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.84      0.83      3231\n",
      "           0       0.26      0.04      0.07       341\n",
      "           1       0.86      0.90      0.88      4437\n",
      "\n",
      "    accuracy                           0.84      8009\n",
      "   macro avg       0.65      0.59      0.59      8009\n",
      "weighted avg       0.82      0.84      0.82      8009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, indices_train, indices_test, tf_vector = create_train_test(tweets_corpus, \"polarity_3_val\", 'lemma_clean_text', custom_stop_words)\n",
    "\n",
    "model_svc, y_predict_svc= train_model(SVC(kernel=\"linear\", tol=1e-7, C=.9),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_rbf, y_predict_rbf = train_model(SVC(kernel=\"rbf\", tol=1e-7, C=.9),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_nb, y_predict_nb = train_model(MultinomialNB(alpha= 0.5),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_LR, y_predict_LR = train_model(LogisticRegression(solver='lbfgs'),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_RF, y_predict_RF = train_model(RandomForestClassifier(max_depth= 14, max_features= 'sqrt',n_estimators= 10),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_GB, y_predict_GB = train_model(GradientBoostingClassifier(max_depth= 14, n_estimators= 500),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_XG, y_predict_XG = train_model(XGBClassifier(eta= 1, gamma= 1, reg_lambda = 5, \n",
    "                                                           max_depth= 12, n_estimators= 500),\n",
    "                                       X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen these models seem to be able to predict positive and negative tweets with an accuracy of around 80-90%, but they just can't seem to be able to detect neutral tweets.\n",
    "\n",
    "To try to improve the models we will try a different approach, we will create models that detect positive tweets, and models that detect negative tweets. We will combine these models into a single one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[4260  518]\n",
      " [ 473 2758]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90      4778\n",
      "           1       0.84      0.85      0.85      3231\n",
      "\n",
      "    accuracy                           0.88      8009\n",
      "   macro avg       0.87      0.87      0.87      8009\n",
      "weighted avg       0.88      0.88      0.88      8009\n",
      "\n",
      "\n",
      "[[4285  493]\n",
      " [ 511 2720]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90      4778\n",
      "           1       0.85      0.84      0.84      3231\n",
      "\n",
      "    accuracy                           0.87      8009\n",
      "   macro avg       0.87      0.87      0.87      8009\n",
      "weighted avg       0.87      0.87      0.87      8009\n",
      "\n",
      "\n",
      "[[4175  603]\n",
      " [ 640 2591]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      4778\n",
      "           1       0.81      0.80      0.81      3231\n",
      "\n",
      "    accuracy                           0.84      8009\n",
      "   macro avg       0.84      0.84      0.84      8009\n",
      "weighted avg       0.84      0.84      0.84      8009\n",
      "\n",
      "\n",
      "[[4330  448]\n",
      " [ 587 2644]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      4778\n",
      "           1       0.86      0.82      0.84      3231\n",
      "\n",
      "    accuracy                           0.87      8009\n",
      "   macro avg       0.87      0.86      0.86      8009\n",
      "weighted avg       0.87      0.87      0.87      8009\n",
      "\n",
      "\n",
      "[[4746   32]\n",
      " [2990  241]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.99      0.76      4778\n",
      "           1       0.88      0.07      0.14      3231\n",
      "\n",
      "    accuracy                           0.62      8009\n",
      "   macro avg       0.75      0.53      0.45      8009\n",
      "weighted avg       0.72      0.62      0.51      8009\n",
      "\n",
      "\n",
      "[[4239  539]\n",
      " [ 648 2583]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      4778\n",
      "           1       0.83      0.80      0.81      3231\n",
      "\n",
      "    accuracy                           0.85      8009\n",
      "   macro avg       0.85      0.84      0.85      8009\n",
      "weighted avg       0.85      0.85      0.85      8009\n",
      "\n",
      "\n",
      "[[4206  572]\n",
      " [ 619 2612]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4778\n",
      "           1       0.82      0.81      0.81      3231\n",
      "\n",
      "    accuracy                           0.85      8009\n",
      "   macro avg       0.85      0.84      0.85      8009\n",
      "weighted avg       0.85      0.85      0.85      8009\n",
      "\n",
      "\n",
      "[[3129  443]\n",
      " [ 477 3960]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      3572\n",
      "           1       0.90      0.89      0.90      4437\n",
      "\n",
      "    accuracy                           0.89      8009\n",
      "   macro avg       0.88      0.88      0.88      8009\n",
      "weighted avg       0.89      0.89      0.89      8009\n",
      "\n",
      "\n",
      "[[3128  444]\n",
      " [ 482 3955]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      3572\n",
      "           1       0.90      0.89      0.90      4437\n",
      "\n",
      "    accuracy                           0.88      8009\n",
      "   macro avg       0.88      0.88      0.88      8009\n",
      "weighted avg       0.88      0.88      0.88      8009\n",
      "\n",
      "\n",
      "[[3063  509]\n",
      " [ 643 3794]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84      3572\n",
      "           1       0.88      0.86      0.87      4437\n",
      "\n",
      "    accuracy                           0.86      8009\n",
      "   macro avg       0.85      0.86      0.85      8009\n",
      "weighted avg       0.86      0.86      0.86      8009\n",
      "\n",
      "\n",
      "[[3092  480]\n",
      " [ 462 3975]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      3572\n",
      "           1       0.89      0.90      0.89      4437\n",
      "\n",
      "    accuracy                           0.88      8009\n",
      "   macro avg       0.88      0.88      0.88      8009\n",
      "weighted avg       0.88      0.88      0.88      8009\n",
      "\n",
      "\n",
      "[[ 892 2680]\n",
      " [ 136 4301]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.25      0.39      3572\n",
      "           1       0.62      0.97      0.75      4437\n",
      "\n",
      "    accuracy                           0.65      8009\n",
      "   macro avg       0.74      0.61      0.57      8009\n",
      "weighted avg       0.73      0.65      0.59      8009\n",
      "\n",
      "\n",
      "[[2958  614]\n",
      " [ 510 3927]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      3572\n",
      "           1       0.86      0.89      0.87      4437\n",
      "\n",
      "    accuracy                           0.86      8009\n",
      "   macro avg       0.86      0.86      0.86      8009\n",
      "weighted avg       0.86      0.86      0.86      8009\n",
      "\n",
      "\n",
      "[[2992  580]\n",
      " [ 570 3867]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      3572\n",
      "           1       0.87      0.87      0.87      4437\n",
      "\n",
      "    accuracy                           0.86      8009\n",
      "   macro avg       0.85      0.85      0.85      8009\n",
      "weighted avg       0.86      0.86      0.86      8009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, indices_train, indices_test, tf_vector = create_train_test(tweets_corpus, \"polarity_neg\", 'lemma_clean_text', custom_stop_words)\n",
    "\n",
    "model_svc_neg, y_predict_svc_neg = train_model(SVC(kernel=\"linear\", tol=1e-7, C=.9),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_rbf_neg, y_predict_rbf_neg = train_model(SVC(kernel=\"rbf\", tol=1e-7, C=.9),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_nb_neg, y_predict_nb_neg = train_model(MultinomialNB(alpha= 0.5),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_LR_neg, y_predict_LR_neg = train_model(LogisticRegression(solver='lbfgs'),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_RF_neg, y_predict_RF_neg = train_model(RandomForestClassifier(max_depth= 14, max_features= 'sqrt',n_estimators= 10),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_GB_neg, y_predict_GB_neg = train_model(GradientBoostingClassifier( \n",
    "                                                           max_depth= 14,n_estimators= 500),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_XG_neg, y_predict_XG_neg = train_model(XGBClassifier(eta= 1, gamma= 1, reg_lambda = 5, \n",
    "                                                           max_depth= 12, n_estimators= 500),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test, tf_vector = create_train_test(tweets_corpus, \"polarity_pos\", 'lemma_clean_text', custom_stop_words)\n",
    "\n",
    "model_svc_pos, y_predict_svc_pos = train_model(SVC(kernel=\"linear\", tol=1e-7, C=.9),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_rbf_pos, y_predict_rbf_pos = train_model(SVC(kernel=\"rbf\", tol=1e-7, C=.9),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_nb_pos, y_predict_nb_pos = train_model(MultinomialNB(alpha= 0.5),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_LR_pos, y_predict_LR_pos = train_model(LogisticRegression(solver='lbfgs'),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_RF_pos, y_predict_RF_pos = train_model(RandomForestClassifier(max_depth= 14, max_features= 'sqrt', n_estimators= 10),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_GB_pos, y_predict_GB_pos = train_model(GradientBoostingClassifier(\n",
    "                                                           max_depth= 14,n_estimators= 500),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_XG_pos, y_predict_XG_pos = train_model(XGBClassifier(eta= 1, gamma= 1, reg_lambda = 5, \n",
    "                                                           max_depth= 12, n_estimators= 500),\n",
    "                                       X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.84      0.85      1759\n",
      "         neu       0.14      0.20      0.17       187\n",
      "         pos       0.91      0.89      0.90      2332\n",
      "\n",
      "    accuracy                           0.84      4278\n",
      "   macro avg       0.64      0.65      0.64      4278\n",
      "weighted avg       0.85      0.84      0.85      4278\n",
      "\n",
      "[[1484  122  153]\n",
      " [  86   38   63]\n",
      " [ 150  108 2074]]\n",
      "rbf results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.84      0.85      1759\n",
      "         neu       0.15      0.21      0.17       187\n",
      "         pos       0.91      0.89      0.90      2332\n",
      "\n",
      "    accuracy                           0.84      4278\n",
      "   macro avg       0.64      0.65      0.64      4278\n",
      "weighted avg       0.85      0.84      0.85      4278\n",
      "\n",
      "[[1475  129  155]\n",
      " [  86   39   62]\n",
      " [ 153   94 2085]]\n",
      "nb results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.79      0.80      1759\n",
      "         neu       0.12      0.20      0.15       187\n",
      "         pos       0.87      0.85      0.86      2332\n",
      "\n",
      "    accuracy                           0.80      4278\n",
      "   macro avg       0.61      0.61      0.61      4278\n",
      "weighted avg       0.82      0.80      0.81      4278\n",
      "\n",
      "[[1383  148  228]\n",
      " [  89   38   60]\n",
      " [ 211  130 1991]]\n",
      "LR results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.83      0.84      1759\n",
      "         neu       0.13      0.18      0.15       187\n",
      "         pos       0.90      0.90      0.90      2332\n",
      "\n",
      "    accuracy                           0.84      4278\n",
      "   macro avg       0.63      0.63      0.63      4278\n",
      "weighted avg       0.85      0.84      0.84      4278\n",
      "\n",
      "[[1452  130  177]\n",
      " [  86   34   67]\n",
      " [ 143   96 2093]]\n",
      "RF results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.94      0.04      0.08      1759\n",
      "         neu       0.07      0.21      0.11       187\n",
      "         pos       0.62      0.97      0.76      2332\n",
      "\n",
      "    accuracy                           0.56      4278\n",
      "   macro avg       0.54      0.41      0.32      4278\n",
      "weighted avg       0.73      0.56      0.45      4278\n",
      "\n",
      "[[  76  424 1259]\n",
      " [   3   39  145]\n",
      " [   2   60 2270]]\n",
      "XG results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.78      0.82      1759\n",
      "         neu       0.12      0.24      0.16       187\n",
      "         pos       0.88      0.86      0.87      2332\n",
      "\n",
      "    accuracy                           0.80      4278\n",
      "   macro avg       0.62      0.63      0.61      4278\n",
      "weighted avg       0.84      0.80      0.82      4278\n",
      "\n",
      "[[1368  185  206]\n",
      " [  73   45   69]\n",
      " [ 157  161 2014]]\n",
      "GB results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.78      0.81      1759\n",
      "         neu       0.12      0.18      0.14       187\n",
      "         pos       0.87      0.88      0.88      2332\n",
      "\n",
      "    accuracy                           0.81      4278\n",
      "   macro avg       0.61      0.61      0.61      4278\n",
      "weighted avg       0.83      0.81      0.82      4278\n",
      "\n",
      "[[1369  145  245]\n",
      " [  90   33   64]\n",
      " [ 164  106 2062]]\n"
     ]
    }
   ],
   "source": [
    "col_name_text = \"lemma_clean_text\"\n",
    "df = test_corpus\n",
    "\n",
    "X_new = tf_vector.transform(np.array(df.loc[:, col_name_text]).ravel())\n",
    "df_predicts = pd.DataFrame()\n",
    "\n",
    "df_predicts[\"predict_svc_neg\"] = model_svc_neg.predict(X_new)\n",
    "df_predicts[\"predict_rbf_neg\"] = model_rbf_neg.predict(X_new)\n",
    "df_predicts[\"predict_nb_neg\"] = model_nb_neg.predict(X_new)\n",
    "df_predicts[\"predict_LR_neg\"] = model_LR_neg.predict(X_new)\n",
    "df_predicts[\"predict_RF_neg\"] = model_RF_neg.predict(X_new)\n",
    "df_predicts[\"predict_GB_neg\"] = model_GB_neg.predict(X_new)\n",
    "df_predicts[\"predict_XG_neg\"] = model_XG_neg.predict(X_new)\n",
    "\n",
    "df_predicts[\"predict_svc_pos\"] = model_svc_pos.predict(X_new)\n",
    "df_predicts[\"predict_rbf_pos\"] = model_rbf_pos.predict(X_new)\n",
    "df_predicts[\"predict_nb_pos\"] = model_nb_pos.predict(X_new)\n",
    "df_predicts[\"predict_LR_pos\"] = model_LR_pos.predict(X_new)\n",
    "df_predicts[\"predict_RF_pos\"] = model_RF_pos.predict(X_new)\n",
    "df_predicts[\"predict_GB_pos\"] = model_GB_pos.predict(X_new)\n",
    "df_predicts[\"predict_XG_pos\"] = model_XG_pos.predict(X_new)\n",
    "\n",
    "def check_model(name_model, df_predicts):\n",
    "    pos_model = \"predict_\" + name_model +\"_pos\"\n",
    "    neg_model = \"predict_\" + name_model +\"_neg\"\n",
    "\n",
    "    conditions = [(df_predicts[pos_model]  == 0) & (df_predicts[neg_model]  == 0),\n",
    "                      (df_predicts[pos_model]  == 1) & (df_predicts[neg_model]  == 1),\n",
    "                (df_predicts[pos_model]  == 1),\n",
    "                (df_predicts[neg_model]  == 1)]\n",
    "    choices = [\"neu\", \"neu\", \"pos\", \"neg\"]\n",
    "    test_corpus[name_model] = np.select(conditions, choices, default='neu')\n",
    "\n",
    "    conditions = [\n",
    "            (test_corpus[\"polarity_3_val\"]  == -1),\n",
    "            (test_corpus[\"polarity_3_val\"]  == 1),\n",
    "            (test_corpus[\"polarity_3_val\"]  == 0)]\n",
    "    choices = [\"neg\", \"pos\", \"neu\"]\n",
    "    test_corpus[\"tag_sent\"] = np.select(conditions, choices, default='NONE')\n",
    "\n",
    "    print(classification_report(test_corpus[\"tag_sent\"], test_corpus[name_model]))\n",
    "    print(confusion_matrix(test_corpus[\"tag_sent\"], test_corpus[name_model]))\n",
    "\n",
    "\n",
    "print(\"svc results:\")\n",
    "check_model(\"svc\",df_predicts)\n",
    "print(\"rbf results:\")\n",
    "check_model(\"rbf\",df_predicts)\n",
    "print(\"nb results:\")\n",
    "check_model(\"nb\",df_predicts)\n",
    "print(\"LR results:\")\n",
    "check_model(\"LR\",df_predicts)\n",
    "print(\"RF results:\")\n",
    "check_model(\"RF\",df_predicts)\n",
    "print(\"XG results:\")\n",
    "check_model(\"XG\",df_predicts)\n",
    "print(\"GB results:\")\n",
    "check_model(\"GB\",df_predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen these combined models seem to work a little better than the multilabel ones. In particular we will choose the Linear SVC to create our full model.\n",
    "\n",
    "First we will save all the models (and the tfidf vector) in case we will want to use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let麓s save the models.\n",
    "path_model = \"D:/sentiment_analysis/models/\"\n",
    "\n",
    "with open(path_model + 'model_svc_neg', 'wb') as picklefile:\n",
    "    pickle.dump(model_svc_neg, picklefile)\n",
    "\n",
    "with open(path_model + 'model_rbf_neg', 'wb') as picklefile:\n",
    "    pickle.dump(model_rbf_neg,picklefile)\n",
    "\n",
    "with open(path_model + 'model_nb_neg', 'wb') as picklefile:\n",
    "    pickle.dump(model_nb_neg,picklefile)\n",
    "\n",
    "with open(path_model + 'model_LR_neg', 'wb') as picklefile:\n",
    "    pickle.dump(model_LR_neg,picklefile)\n",
    "\n",
    "with open(path_model + 'model_RF_neg', 'wb') as picklefile:\n",
    "    pickle.dump(model_RF_neg,picklefile)\n",
    "    \n",
    "with open(path_model + 'model_GB_neg', 'wb') as picklefile:\n",
    "    pickle.dump(model_GB_neg,picklefile)\n",
    "\n",
    "with open(path_model + 'model_XG_neg', 'wb') as picklefile:\n",
    "    pickle.dump(model_XG_neg,picklefile)\n",
    "    \n",
    "with open(path_model + 'model_svc_pos', 'wb') as picklefile:\n",
    "    pickle.dump(model_svc_pos,picklefile)\n",
    "\n",
    "with open(path_model + 'model_rbf_pos', 'wb') as picklefile:\n",
    "    pickle.dump(model_rbf_pos,picklefile)\n",
    "\n",
    "with open(path_model + 'model_nb_pos', 'wb') as picklefile:\n",
    "    pickle.dump(model_nb_pos,picklefile)\n",
    "\n",
    "with open(path_model + 'model_LR_pos', 'wb') as picklefile:\n",
    "    pickle.dump(model_LR_pos,picklefile)\n",
    "\n",
    "with open(path_model + 'model_RF_pos', 'wb') as picklefile:\n",
    "    pickle.dump(model_RF_pos,picklefile)\n",
    "    \n",
    "with open(path_model + 'model_GB_pos', 'wb') as picklefile:\n",
    "    pickle.dump(model_GB_pos,picklefile)\n",
    "\n",
    "with open(path_model + 'model_XG_pos', 'wb') as picklefile:\n",
    "    pickle.dump(model_XG_pos,picklefile)\n",
    "\n",
    "with open(path_model + 'vectorizer.pk', 'wb') as fin:\n",
    "     pickle.dump(tf_vector, fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will combine all of the pieces of this model into one class that will be used to predict the sentiment of new texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis:\n",
    "    \n",
    "    path_model = \"D:/sentiment_analysis/models/\"\n",
    "    with open(path_model + 'model_svc_neg', 'rb') as training_model:\n",
    "        model_svc_neg = pickle.load(training_model)\n",
    "\n",
    "    with open(path_model + 'model_svc_pos', 'rb') as training_model:\n",
    "        model_svc_pos = pickle.load(training_model)\n",
    "\n",
    "    with open(path_model + 'vectorizer.pk', 'rb') as fin:\n",
    "        tf_vector = pickle.load(fin)\n",
    "    \n",
    "    def create_custom_stop_words(self, list_new_stopwords, remove_words):\n",
    "        custom_stop_words = list(set(stopwords.words('spanish')))\n",
    "        custom_stop_words.extend(list_new_stopwords)\n",
    "        custom_stop_words = [word for word in custom_stop_words if word not in remove_words]\n",
    "        return custom_stop_words\n",
    "\n",
    "    def lemmatizer(self, text,nlp):\n",
    "        sent = []\n",
    "        doc = nlp(text)\n",
    "        for word in doc:\n",
    "            sent.append(word.lemma_)\n",
    "        return \" \".join(sent)\n",
    "\n",
    "    def clean_text(self, s):\n",
    "        filters = [gsp.strip_tags,\n",
    "                   gsp.strip_punctuation,\n",
    "                   gsp.strip_multiple_whitespaces,\n",
    "                   gsp.strip_numeric]\n",
    "        s = re.sub(r'http\\S+', '', s)\n",
    "        s = s.lower()\n",
    "        s = utils.to_unicode(s)\n",
    "        s = utils.deaccent(s)\n",
    "        for f in filters:\n",
    "            s = f(s)\n",
    "        return s\n",
    "    \n",
    "    def preprocess(self, text, list_new_stopwords, remove_words, nlp):\n",
    "        custom_stop_words = self.create_custom_stop_words(list_new_stopwords, remove_words)\n",
    "        text = ' '.join([word for word in text.split() if word not in (custom_stop_words)])\n",
    "        text = self.clean_text(text)\n",
    "        text = self.lemmatizer(text, nlp)\n",
    "        return text\n",
    "    \n",
    "    def get_sentiment(self, text, model_neg= model_svc_neg, model_pos=model_svc_pos , vector= tf_vector):\n",
    "        stopwords_nltk = set(stopwords.words('spanish'))\n",
    "        exclude = set(string.punctuation)\n",
    "        lemma = WordNetLemmatizer()\n",
    "        nlp = spacy.load(\"es_core_news_sm\")\n",
    "        nlp.add_pipe(lemmatize, after=\"tagger\")\n",
    "\n",
    "        list_new_stopwords = [\"aun\", \"ser\", \"ver\", \"hoy\", \"ustedes\", \"aqui\",\n",
    "                                      \"vamos\", \"haber\", \"hacer\", \"tener\", \"ir\",\n",
    "                                      \"decir\", \"comer\",\"asi\", \"pues\"]\n",
    "        remove_words = [\"no\", \"si\", \"s铆\"]\n",
    "        text = self.preprocess(text, list_new_stopwords, remove_words, nlp)\n",
    "        \n",
    "        X_new = vector.transform([text])\n",
    "\n",
    "        predict_svc_neg = model_neg.predict(X_new)\n",
    "        predict_svc_pos = model_pos.predict(X_new)\n",
    "\n",
    "        pred = \"\"\n",
    "        if (predict_svc_neg[0]== 1) & (predict_svc_pos[0]== 1):\n",
    "            pred = \"mix\"\n",
    "        elif (predict_svc_neg[0]== 0) & (predict_svc_pos[0]== 0):\n",
    "            pred = \"neutral\"\n",
    "        elif (predict_svc_neg[0]== 1) & (predict_svc_pos[0]== 0):\n",
    "            pred = \"negative\"\n",
    "        elif (predict_svc_neg[0]== 0)  & (predict_svc_pos[0]== 1):\n",
    "            pred = \"positive\"\n",
    "        return pred\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = SentimentAnalysis()\n",
    "text = \"odio este programa de television\"\n",
    "sentiment.get_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Me encanta este programa de television\"\n",
    "sentiment.get_sentiment(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Mi modelo funciona\"\n",
    "sentiment.get_sentiment(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Mi no modelo funciona\"\n",
    "sentiment.get_sentiment(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
